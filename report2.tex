\documentclass[11pt,a4paper,oneside]{report}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\begin{document}
\title{HPSC Assignment 2}
\author{Gregory Petropoulos}
\date{September 19, 2012}
\maketitle

\section{Communication Diagram and Basic Checks}

Figure \ref{fig:nodecomm} shows node to node diagrams for communicating a MPI Allreduce across eight nodes.  Figure \ref{fig:lowtohighout} shows the output generated by my code in verbose mode, where it prints out the node communications at each step, matches the diagram in figure \ref{fig:lowtohigh}.  Figure \ref{fig:hightolowout} shows the output generated by my code in verbose mode matches the diagram in figure \ref{fig:hightolow}.  Finally, figure \ref{fig:matchingcores} shows that every core has the correct answer at the end of the program's execution.  Since this output is identical for both high to low and low to high bit traversals I only provided the output once.

\begin{figure}[htpb]
  \centering
  \begin{subfigure}[b]{2.4in}
    \centering
    \includegraphics[width=2.4in]{Figures/lowtohigh.jpg}
    \caption{Low to high bit traversal.}
    \label{fig:lowtohigh}
  \end{subfigure}
  \begin{subfigure}[b]{2.4in}
    \centering
    \includegraphics[width=2.4in]{Figures/hightolow.jpg}
    \caption{High to low bit traversal.}
    \label{fig:hightolow}
  \end{subfigure}
  \caption{Node communication diagram showing how data is transmitted in an eight-node network for the butterfly all reduce algorithm.}\label{fig:nodecomm}
\end{figure}

\begin{figure}[htpb]
  \texttt{[4/8:   0] : Process 4:  stage 1, receiving from 5\\}
  \texttt{[2/8:   0] : Process 2:  stage 1, receiving from 3\\}
  \texttt{[6/8:   0] : Process 6:  stage 1, receiving from 7\\}
  \texttt{[1/8:   0] : Process 1:  stage 1, sending to 0\\}
  \texttt{[0/8:   1] : Process 0:  stage 1, receiving from 1\\}
  \texttt{[0/8:   2] : Process 0:  stage 2, receiving from 2\\}
  \texttt{[3/8:   0] : Process 3:  stage 1, sending to 2\\}
  \texttt{[2/8:   1] : Process 2:  stage 2, sending to 0\\}
  \texttt{[5/8:   0] : Process 5:  stage 1, sending to 4\\}
  \texttt{[1/8:   1] : Process 1:  stage 2, receiving from 3\\}
  \texttt{[0/8:   3] : Process 0:  stage 3, receiving from 4\\}
  \texttt{[7/8:   0] : Process 7:  stage 1, sending to 6\\}
  \texttt{[6/8:   1] : Process 6:  stage 2, sending to 4\\}
  \texttt{[4/8:   1] : Process 4:  stage 2, receiving from 6\\}
  \texttt{[4/8:   2] : Process 4:  stage 3, sending to 0\\}
  \texttt{[6/8:   2] : Process 6:  stage 3, sending to 2\\}
  \texttt{[3/8:   1] : Process 3:  stage 2, sending to 1\\}
  \texttt{[2/8:   2] : Process 2:  stage 3, receiving from 6\\}
  \texttt{[5/8:   1] : Process 5:  stage 2, receiving from 7\\}
  \texttt{[1/8:   2] : Process 1:  stage 3, receiving from 5\\}
  \texttt{[7/8:   1] : Process 7:  stage 2, sending to 5\\}
  \texttt{[3/8:   2] : Process 3:  stage 3, receiving from 7\\}
  \texttt{[5/8:   2] : Process 5:  stage 3, sending to 1\\}
  \texttt{[7/8:   2] : Process 7:  stage 3, sending to 3\\}
  \caption{Verbose output for low to high bit traversal.}
  \label{fig:lowtohighout}
\end{figure}
\begin{figure}[htpb]
  \texttt{[7/8:   0] : Process 7:  stage 1, receiving from 3\\}
  \texttt{[0/8:   1] : Process 0:  stage 1, sending to 4\\}
  \texttt{[3/8:   0] : Process 3:  stage 1, sending to 7\\}
  \texttt{[7/8:   1] : Process 7:  stage 2, receiving from 5\\}
  \texttt{[3/8:   1] : Process 3:  stage 2, receiving from 1\\}
  \texttt{[1/8:   0] : Process 1:  stage 1, sending to 5\\}
  \texttt{[5/8:   0] : Process 5:  stage 1, receiving from 1\\}
  \texttt{[2/8:   0] : Process 2:  stage 1, sending to 6\\}
  \texttt{[6/8:   0] : Process 6:  stage 1, receiving from 2\\}
  \texttt{[4/8:   0] : Process 4:  stage 1, receiving from 0\\}
  \texttt{[4/8:   1] : Process 4:  stage 2, sending to 6\\}
  \texttt{[0/8:   2] : Process 0:  stage 2, sending to 2\\}
  \texttt{[5/8:   1] : Process 5:  stage 2, sending to 7\\}
  \texttt{[1/8:   1] : Process 1:  stage 2, sending to 3\\}
  \texttt{[3/8:   2] : Process 3:  stage 3, receiving from 2\\}
  \texttt{[7/8:   2] : Process 7:  stage 3, receiving from 6\\}
  \texttt{[1/8:   2] : Process 1:  stage 3, receiving from 0\\}
  \texttt{[2/8:   1] : Process 2:  stage 2, receiving from 0\\}
  \texttt{[2/8:   2] : Process 2:  stage 3, sending to 3\\}
  \texttt{[4/8:   2] : Process 4:  stage 3, sending to 5\\}
  \texttt{[6/8:   1] : Process 6:  stage 2, receiving from 4\\}
  \texttt{[6/8:   2] : Process 6:  stage 3, sending to 7\\}
  \texttt{[0/8:   3] : Process 0:  stage 3, sending to 1\\}
  \texttt{[5/8:   2] : Process 5:  stage 3, receiving from 4\\}
  \caption{Verbose output for high to low bit traversal.}
  \label{fig:hightolowout}
\end{figure}
\begin{figure}[htpb]
  \texttt{[1/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[3/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[2/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[5/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[7/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[6/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[4/8:  30] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \texttt{[0/8:  50] : The answer is [0, 0.008, 0.016, 0.024, 0.032, 0.04, 0.048, 0.056, 0.064, 0.072]\\}
  \caption{Verbose output showing every core has the correct answer.}
  \label{fig:matchingcores}
\end{figure}
\pagebreak
\section{Timings on Gordon}

I ran 10 timings for each test to allow for warm-ups and get reasonable statistics.  As the attached timing tables show, not not many warm-ups were needed for most of the tests.  To keep the statistics constant, I removed the same number of warm-ups for a given test.  For the latency test I removed two warm-ups and for the throughput test I removed five warm-ups.  For the throughput test the 8 byte low to high test took an abnormally long time to equilibrate, which caused me to make an across the board cut in statistics for this test.  While the timing tables show that the MPI Allreduce consistently required the shortest number of warm-ups this is somewhat deceptive because the MPI calls were always run after the my calls.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=4in]{Figures/Throughput.png}
  \caption{Throughput bound analysis, note the log-log scale.}
  \label{fig:throughput}
\end{figure}

\begin{figure}[htpb]
  \centering
  \includegraphics[width=4in]{Figures/Latency.png}
  \caption{Latency bound analysis with an eight kilobyte message, note the log-log scale.}
  \label{fig:latency}
\end{figure}

\section{Answers to Questions}
My implementation held its own in the latency tests.  Here the MPI Allreduce average timings were slightly lower than mine but they were within errors.   The MPI Allreduce performed significantly better than my implementation in the throughput tests for messages larger than one kilobyte.  I suspect that MPI has some built way to better control how large chunks of memory are passed that I did not include in my implementation.

In both tests the order of the bit traversal in my implementation did not matter.  I expected this because the only difference between high to low and low to high is the order in which the different processes talk to each other, not the overall distance that the message has to go.

Overall large vector sizes and large numbers of cores degrade performance.  Large vector sizes degrade performance because passing large amounts of data takes time on the interconnect which is a bottleneck.  Large numbers of cores degrade performance because the more cores you have the more communication steps you need.  Again this means more time on the interconnect which is a bottleneck.  That being said there are many problems that would not be solvable without passing large amounts of data or using a large number of cores.  The moreal of the story is run timings, minimize communication, and optimize.

\end{document}
